#!/usr/bin/env python3
"""
ìˆ˜ì§‘ëœ ë…¼ë¬¸ì„ Notion ë°ì´í„°ë² ì´ìŠ¤ì— push
Usage: python push_to_notion.py [data/spinej_2026_*.json]
       python push_to_notion.py --latest          # ê°€ì¥ ìµœê·¼ íŒŒì¼
       python push_to_notion.py --all             # data/ ì „ì²´
"""

import json
import os
import sys
import glob
import urllib.request
import urllib.error
import time
from datetime import datetime
from llm_utils import check_llm_available, summarize_and_translate as llm_summarize

# â”€â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CONFIG_PATH = os.path.join(os.path.dirname(__file__), "config.json")

def load_config():
    with open(CONFIG_PATH, "r") as f:
        return json.load(f)

def notion_api(endpoint: str, data: dict, token: str, method="POST") -> dict | None:
    """Notion API í˜¸ì¶œ"""
    url = f"https://api.notion.com/v1/{endpoint}"
    body = json.dumps(data).encode("utf-8")

    req = urllib.request.Request(url, data=body, method=method, headers={
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json",
        "Notion-Version": "2022-06-28",
    })

    try:
        with urllib.request.urlopen(req, timeout=30) as resp:
            return json.loads(resp.read())
    except urllib.error.HTTPError as e:
        error_body = e.read().decode()
        print(f"  âŒ Notion API ì˜¤ë¥˜ ({e.code}): {error_body[:200]}")
        return None

def query_existing(database_id: str, token: str) -> set:
    """ì´ë¯¸ ë“±ë¡ëœ ë…¼ë¬¸ PMID ëª©ë¡ ì¡°íšŒ"""
    existing = set()
    has_more = True
    start_cursor = None

    while has_more:
        payload = {"page_size": 100}
        if start_cursor:
            payload["start_cursor"] = start_cursor

        result = notion_api(f"databases/{database_id}/query", payload, token)
        if not result:
            break

        for page in result.get("results", []):
            props = page.get("properties", {})
            # DOIë¡œ ì¤‘ë³µ ì²´í¬
            doi_prop = props.get("DOI", {})
            if doi_prop.get("url"):
                existing.add(doi_prop["url"])
            # Titleë¡œë„ ì²´í¬
            title_prop = props.get("Title", {})
            titles = title_prop.get("title", [])
            if titles:
                existing.add(titles[0].get("plain_text", "").strip()[:50])

        has_more = result.get("has_more", False)
        start_cursor = result.get("next_cursor")

    return existing





# â”€â”€â”€ ê´€ì‹¬ë„/ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def classify_interest(article: dict, config: dict) -> str:
    """ê´€ì‹¬ë„ ìë™ ë¶„ë¥˜"""
    title_lower = article.get("title", "").lower()
    abstract_lower = article.get("abstract", "").lower()
    keywords_lower = " ".join(article.get("keywords", [])).lower()
    mesh_lower = " ".join(article.get("mesh_terms", [])).lower()
    all_text = f"{title_lower} {abstract_lower} {keywords_lower} {mesh_lower}"

    # ë…¼ë¬¸ ìœ í˜• í•„í„° (Letter, Erratum ë“±ì€ ì°¸ê³ )
    pub_types = [pt.lower() for pt in article.get("pub_types", [])]
    low_priority_types = ["letter", "comment", "erratum", "published erratum", "editorial"]
    if any(lpt in pt for pt in pub_types for lpt in low_priority_types):
        return "âšª ì°¸ê³ "

    # í•„ë… í‚¤ì›Œë“œ
    must_read = config.get("interest_keywords", {}).get("must_read", [])
    for kw in must_read:
        if kw.lower() in all_text:
            return "ğŸ”´ í•„ë…"

    # ê´€ì‹¬ í‚¤ì›Œë“œ
    interested = config.get("interest_keywords", {}).get("interested", [])
    match_count = sum(1 for kw in interested if kw.lower() in all_text)
    if match_count >= 2:
        return "ğŸ”´ í•„ë…"
    elif match_count >= 1:
        return "ğŸŸ¡ ê´€ì‹¬"

    return "âšª ì°¸ê³ "


def classify_pub_type(article: dict) -> str:
    """ë…¼ë¬¸ ìœ í˜• ë¶„ë¥˜ (Journal Type)"""
    pub_types = [pt.lower() for pt in article.get("pub_types", [])]

    # ìš°ì„ ìˆœìœ„ìˆœ ë§¤í•‘
    if any("randomized controlled trial" in pt for pt in pub_types):
        return "RCT"
    if any("meta-analysis" in pt for pt in pub_types):
        return "Meta-analysis"
    if any("systematic review" in pt for pt in pub_types):
        return "Systematic Review"
    if any("review" in pt for pt in pub_types):
        return "Review"
    if any("editorial" in pt for pt in pub_types):
        return "Editorial"
    if any("letter" in pt for pt in pub_types):
        return "Letter to Editor"
    if any("comment" in pt for pt in pub_types):
        return "Letter to Editor"
    if any("published erratum" in pt or "erratum" in pt for pt in pub_types):
        return "Erratum"
    if any("case reports" in pt for pt in pub_types):
        return "Case Report"
    if any("observational" in pt for pt in pub_types):
        return "Observational Study"
    if any("comparative study" in pt for pt in pub_types):
        return "Comparative Study"
    if any("multicenter study" in pt for pt in pub_types):
        return "Multicenter Study"
    if any("validation study" in pt for pt in pub_types):
        return "Validation Study"
    if any("historical article" in pt for pt in pub_types):
        return "Historical Article"

    return "Clinical Study"


def auto_categorize(article: dict, config: dict) -> list[str]:
    """ìë™ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
    categories = []
    all_text = (
        article.get("title", "") + " " +
        article.get("abstract", "") + " " +
        " ".join(article.get("keywords", [])) + " " +
        " ".join(article.get("mesh_terms", []))
    ).lower()

    category_rules = config.get("category_rules", {})
    for cat_name, keywords in category_rules.items():
        for kw in keywords:
            if kw.lower() in all_text:
                categories.append(cat_name)
                break

    # Pub type ê¸°ë°˜
    pub_types = [pt.lower() for pt in article.get("pub_types", [])]
    if any("review" in pt for pt in pub_types):
        if "Review" not in categories:
            categories.append("Review")
    if any("meta-analysis" in pt for pt in pub_types):
        if "Meta-analysis" not in categories:
            categories.append("Meta-analysis")
    if any("randomized" in pt for pt in pub_types):
        if "RCT" not in categories:
            categories.append("RCT")

    return categories


# â”€â”€â”€ Notion í˜ì´ì§€ ë¸”ë¡ êµ¬ì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_abstract_blocks(abstract: str, translation: str) -> list[dict]:
    """í˜ì´ì§€ ë³¸ë¬¸ì— ë“¤ì–´ê°ˆ Abstract ë¸”ë¡ë“¤"""
    blocks = []

    if abstract:
        # English heading
        blocks.append({
            "object": "block",
            "type": "heading_2",
            "heading_2": {
                "rich_text": [{"type": "text", "text": {"content": "Abstract"}}]
            }
        })
        # English body â€” 2000ì ì œí•œ ì²˜ë¦¬
        for chunk in _chunk_text(abstract, 2000):
            blocks.append({
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"type": "text", "text": {"content": chunk}}]
                }
            })

    if translation:
        # Divider
        blocks.append({"object": "block", "type": "divider", "divider": {}})
        # Korean heading
        blocks.append({
            "object": "block",
            "type": "heading_2",
            "heading_2": {
                "rich_text": [{"type": "text", "text": {"content": "í•œê¸€ ë²ˆì—­"}}]
            }
        })
        # Korean body
        for chunk in _chunk_text(translation, 2000):
            blocks.append({
                "object": "block",
                "type": "paragraph",
                "paragraph": {
                    "rich_text": [{"type": "text", "text": {"content": chunk}}]
                }
            })

    return blocks


def _chunk_text(text: str, size: int) -> list[str]:
    """í…ìŠ¤íŠ¸ë¥¼ size ë‹¨ìœ„ë¡œ ë¶„í• """
    if len(text) <= size:
        return [text]
    chunks = []
    while text:
        chunks.append(text[:size])
        text = text[size:]
    return chunks


# â”€â”€â”€ Notion í˜ì´ì§€ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def create_notion_page(article: dict, database_id: str, token: str,
                       config: dict, use_llm: bool = False) -> bool:
    interest = classify_interest(article, config)

    journal_key = article.get("_journal_key", "")
    journal_name = article.get("journal_abbr", "") or article.get("journal", "")
    if journal_key and journal_key in config.get("journals", {}):
        journal_name = config["journals"][journal_key]["name"]

    categories = auto_categorize(article, config)
    journal_type = classify_pub_type(article)

    abstract = article.get("abstract", "")
    if use_llm:
        summary_ko, translation_ko = llm_summarize(article["title"], abstract, config)
    else:
        summary_ko = abstract[:100] if abstract else ""
        translation_ko = ""

    # Properties êµ¬ì„±
    properties = {
        "Title": {
            "title": [{"text": {"content": article["title"][:2000]}}]
        },
        "Author": {
            "rich_text": [{"text": {"content": article.get("authors", "")[:2000]}}]
        },
        "Journal Name": {
            "select": {"name": journal_name[:100]} if journal_name else None
        },
        "Summary": {
            "rich_text": [{"text": {"content": summary_ko[:2000]}}]
        },
        "ê´€ì‹¬ë„": {
            "select": {"name": interest}
        },
        "ì½ìŒ": {
            "checkbox": False
        },
        "Type": {
            "select": {"name": journal_type}
        },
    }

    if article.get("affiliation"):
        properties["Affiliations"] = {
            "rich_text": [{"text": {"content": article["affiliation"][:2000]}}]
        }

    if article.get("volume"):
        properties["Vol"] = {"rich_text": [{"text": {"content": article["volume"]}}]}
    if article.get("issue"):
        properties["Issue"] = {"rich_text": [{"text": {"content": article["issue"]}}]}

    # DOI URL
    if article.get("doi_url"):
        properties["DOI"] = {"url": article["doi_url"]}

    # Publication Date
    if article.get("pub_date"):
        date_str = article["pub_date"]
        if len(date_str) == 4:
            date_str = f"{date_str}-01-01"
        elif len(date_str) == 7:
            date_str = f"{date_str}-01"
        properties["Publication Date"] = {"date": {"start": date_str}}

    # Keywords
    if article.get("keywords"):
        properties["Keywords"] = {
            "multi_select": [{"name": kw[:100]} for kw in article["keywords"][:5]]
        }

    # Category
    if categories:
        properties["Category"] = {
            "multi_select": [{"name": cat} for cat in categories[:5]]
        }

    # None ì œê±°
    properties = {k: v for k, v in properties.items() if v is not None}

    # í˜ì´ì§€ ë³¸ë¬¸ ë¸”ë¡ (ì˜ë¬¸ Abstract + í•œê¸€ ë²ˆì—­)
    children = build_abstract_blocks(abstract, translation_ko)

    payload = {
        "parent": {"database_id": database_id},
        "properties": properties,
    }
    if children:
        payload["children"] = children

    result = notion_api("pages", payload, token)
    return result is not None


# â”€â”€â”€ ë©”ì¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    config = load_config()

    # Notion í† í° í™•ì¸
    token = os.environ.get("NOTION_TOKEN") or config.get("notion_token", "")
    if not token:
        print("âŒ NOTION_TOKEN í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” config.jsonì— notion_token ì„¤ì • í•„ìš”")
        print("   export NOTION_TOKEN='ntn_...'")
        sys.exit(1)

    use_llm, llm_backend = check_llm_available(config)
    if use_llm:
        print(f"ğŸ¤– LLM ê°ì§€: {llm_backend} â€” í•œê¸€ ìš”ì•½/ë²ˆì—­ ìƒì„±")
    else:
        print("âš ï¸  LLM ë¯¸ì„¤ì • â€” í•œê¸€ ìš”ì•½/ë²ˆì—­ ì—†ì´ ì§„í–‰ (OPENAI_API_KEY ë˜ëŠ” ANTHROPIC_API_KEY ì„¤ì • í•„ìš”)")

    database_id = config["notion_database_id"]

    # ì…ë ¥ íŒŒì¼ ê²°ì •
    data_dir = os.path.join(os.path.dirname(__file__), "data")

    if len(sys.argv) > 1 and sys.argv[1] == "--latest":
        files = glob.glob(os.path.join(data_dir, "*.json"))
        if not files:
            print("âŒ data/ ì— JSON íŒŒì¼ ì—†ìŒ. fetch_papers.py ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            sys.exit(1)
        input_files = [max(files, key=os.path.getmtime)]
    elif len(sys.argv) > 1 and sys.argv[1] == "--all":
        input_files = sorted(glob.glob(os.path.join(data_dir, "*.json")))
    elif len(sys.argv) > 1:
        input_files = sys.argv[1:]
    else:
        files = sorted(glob.glob(os.path.join(data_dir, "*.json")))
        if not files:
            print("âŒ data/ ì— JSON íŒŒì¼ ì—†ìŒ")
            sys.exit(1)
        input_files = [files[-1]]

    # ê¸°ì¡´ ë…¼ë¬¸ ëª©ë¡ ì¡°íšŒ (ì¤‘ë³µ ë°©ì§€)
    print("ğŸ“‹ ê¸°ì¡´ Notion DB ì¡°íšŒ ì¤‘...")
    existing = query_existing(database_id, token)
    print(f"   ê¸°ì¡´ {len(existing)}ê±´ ë“±ë¡ë¨")

    # ë…¼ë¬¸ push
    total_new = 0
    total_skip = 0

    for filepath in input_files:
        print(f"\nğŸ“‚ {os.path.basename(filepath)}")
        with open(filepath, "r", encoding="utf-8") as f:
            articles = json.load(f)

        for i, article in enumerate(articles):
            # ì¤‘ë³µ ì²´í¬
            doi_url = article.get("doi_url", "")
            title_key = article.get("title", "").strip()[:50]

            if doi_url in existing or title_key in existing:
                total_skip += 1
                continue

            interest = classify_interest(article, config)
            emoji = "ğŸ”´" if "í•„ë…" in interest else "ğŸŸ¡" if "ê´€ì‹¬" in interest else "âšª"

            success = create_notion_page(article, database_id, token, config, use_llm)
            if success:
                total_new += 1
                existing.add(doi_url)
                existing.add(title_key)
                print(f"  {emoji} [{i+1}/{len(articles)}] {article['title'][:60]}...")
            else:
                print(f"  âŒ [{i+1}/{len(articles)}] ì‹¤íŒ¨: {article['title'][:40]}...")

            time.sleep(0.35)  # Notion rate limit

    print(f"\nâœ… ì™„ë£Œ: ìƒˆë¡œ ì¶”ê°€ {total_new}ê±´, ì¤‘ë³µ ìŠ¤í‚µ {total_skip}ê±´")
    return total_new

if __name__ == "__main__":
    result = main()
    sys.exit(0 if result is None or result > 0 else 2)
